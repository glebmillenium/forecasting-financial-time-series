FANN_FLO_2.1
num_layers=3
learning_rate=0,700000
connection_rate=1,000000
network_type=0
learning_momentum=0,000000
training_algorithm=0
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0,010000
quickprop_decay=-0,000100
quickprop_mu=1,750000
rprop_increase_factor=1,200000
rprop_decrease_factor=0,500000
rprop_delta_min=0,000000
rprop_delta_max=50,000000
rprop_delta_zero=0,100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0,010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3,49999994039535522461e-01
cascade_candidate_limit=1,00000000000000000000e+03
cascade_weight_multiplier=4,00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2,50000000000000000000e-01 5,00000000000000000000e-01 7,50000000000000000000e-01 1,00000000000000000000e+00 
layer_sizes=20 6 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (0, 0, 0,00000000000000000000e+00) (20, 5, 5,00000000000000000000e-01) (20, 5, 5,00000000000000000000e-01) (20, 5, 5,00000000000000000000e-01) (20, 5, 5,00000000000000000000e-01) (20, 5, 5,00000000000000000000e-01) (0, 5, 0,00000000000000000000e+00) (6, 5, 5,00000000000000000000e-01) (0, 5, 0,00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1,00789320468902587891e+00) (1, -1,05416160076856613159e-02) (2, -4,13228645920753479004e-02) (3, 3,34443211555480957031e-01) (4, -7,25836038589477539062e-01) (5, 1,71956449747085571289e-01) (6, -3,26999336481094360352e-01) (7, 5,34497976303100585938e-01) (8, -2,20244437456130981445e-01) (9, -6,25980868935585021973e-02) (10, 3,84210124611854553223e-02) (11, 2,82974332571029663086e-01) (12, 2,10806936025619506836e-01) (13, -2,57765322923660278320e-01) (14, 7,78134524822235107422e-01) (15, -7,38543793559074401855e-02) (16, -8,87487009167671203613e-02) (17, 2,60587453842163085938e-01) (18, -1,56643301248550415039e-01) (19, -2,17677384614944458008e-01) (0, 6,90405547618865966797e-01) (1, 2,95576333999633789062e-01) (2, 4,40859287977218627930e-01) (3, 1,17866776883602142334e-01) (4, 3,12501043081283569336e-01) (5, 1,40829950571060180664e-01) (6, 1,32947117090225219727e-01) (7, 5,56892991065979003906e-01) (8, -1,52025774121284484863e-01) (9, 3,36405970156192779541e-02) (10, -1,37003138661384582520e-02) (11, 8,53730887174606323242e-02) (12, 4,05904591083526611328e-01) (13, 5,13008952140808105469e-01) (14, 6,10078275203704833984e-01) (15, 3,21244388818740844727e-01) (16, -8,47975350916385650635e-03) (17, 4,48114871978759765625e-01) (18, 1,67486563324928283691e-01) (19, 2,60420560836791992188e-01) (0, 4,82687532901763916016e-01) (1, 5,77389657497406005859e-01) (2, 4,72852513194084167480e-02) (3, 3,67362260818481445312e-01) (4, 3,64916771650314331055e-01) (5, 4,75305974483489990234e-01) (6, 3,52401882410049438477e-01) (7, 3,49834501743316650391e-01) (8, 4,01868298649787902832e-02) (9, 3,96721065044403076172e-01) (10, 4,32468175888061523438e-01) (11, 5,49327731132507324219e-01) (12, 3,18622499704360961914e-01) (13, 6,68770134449005126953e-01) (14, 1,93156152963638305664e-01) (15, 2,22483977675437927246e-01) (16, 5,61542809009552001953e-02) (17, 3,95270168781280517578e-01) (18, 2,27251186966896057129e-01) (19, -5,63370771706104278564e-02) (0, 4,58468735218048095703e-01) (1, 2,96393126249313354492e-01) (2, 5,81955425441265106201e-02) (3, 3,30168724060058593750e-01) (4, -9,64024066925048828125e-02) (5, 1,57660320401191711426e-01) (6, -9,39765498042106628418e-02) (7, 3,91633957624435424805e-01) (8, -1,30475368350744247437e-02) (9, 1,06569230556488037109e-01) (10, -1,29668012261390686035e-01) (11, 3,45993191003799438477e-01) (12, 4,30263608694076538086e-01) (13, 4,22221958637237548828e-01) (14, 3,98249268531799316406e-01) (15, 2,64204323291778564453e-01) (16, -1,06415614485740661621e-01) (17, 5,28296887874603271484e-01) (18, 4,49368268251419067383e-01) (19, 1,57340392470359802246e-01) (0, 1,17113995552062988281e+00) (1, 3,62062789499759674072e-02) (2, -3,90362948179244995117e-01) (3, 3,63301187753677368164e-01) (4, -1,15489029884338378906e+00) (5, -2,56393164396286010742e-01) (6, -6,65326058864593505859e-01) (7, 2,02896833419799804688e-01) (8, -7,58333444595336914062e-01) (9, -7,02036023139953613281e-01) (10, -3,80766361951828002930e-01) (11, -1,34372785687446594238e-02) (12, -5,79106211662292480469e-01) (13, 6,42374157905578613281e-02) (14, 1,07660412788391113281e+00) (15, 5,23904323577880859375e-01) (16, -1,14494301378726959229e-01) (17, 7,04190909862518310547e-01) (18, -4,78802323341369628906e-01) (19, -7,51273259520530700684e-02) (20, 1,40610146522521972656e+00) (21, 1,08785820007324218750e+00) (22, 6,43644869327545166016e-01) (23, 1,11052131652832031250e+00) (24, 2,41209840774536132812e+00) (25, 3,98613303899765014648e-01) 
